#!/usr/bin/env python
# encoding: utf-8
"""
quickjunc

This takes BAM files as input, and calculates coverage for junctions.
Calculates total coverage and filtered coverage where
minimum anchor size >= X

The version quickjunc_from_junclist allows the input of a junction list to quantify from

"""
from __future__ import division 

import re
import sys
import argparse
import pysam
import csv
import math
import os
import collections

from datetime import datetime, date
#from argparse import RawTextHelpFormatter

import spanki.spanki_utils as spanki_utils

class Junctionid:
	"""
	Base class for a junction, from juncid
	Expects junction id
	"""
	def __init__(self, juncid):
		chr = juncid.split(':')[0]
		coords = juncid.split(':')[1]
		strand = juncid.split(':')[2]
		start = int(coords.split('_')[0]) - 1
		end = int(coords.split('_')[1])
		self.chr = chr
		self.start = start
		self.end = end
		self.strand = strand.strip()
		self.intronsize = end - start
		#self.accid = str(coords.split('_')[0])
		if self.strand == "+":
			self.donid = chr + ":" + str(start)
			self.accid = chr + ":" + str(end)
		elif self.strand == "-":
			self.accid = chr + ":" + str(start)
			self.donid = chr + ":" + str(end)
		else:
			print "strand character is", self.strand
			quit("Don't recognize strand")
			
class JuncBasic:
	"""
	Base class for a junction
	Expects SAM input
	"""
	def __init__(self, chr, start, cigar, readseq, tags):
		self.chr = chr
		self.start = start
		self.cigar = cigar
		self.readseq = readseq
		## anchorsize is the genomic coordinate space (accounting for indels)
		## The aligned portion may be longer or shorter after indels
		left_anchorsize = 0
		left_read_anchor = ""
		left_genome_aligned = ""
		right_anchorsize = 0
		right_read_anchor = ""
		right_genome_aligned = ""
		gapsize = 0
		gap_seen = 0
		readpos = 0
		genomepos = self.start
		for i in self.cigar:
			if i[0] == 0:
				if gap_seen < 1:
					left_anchorsize += i[1]
					left_read_anchor += self.readseq[readpos:readpos + i[1]]
					left_genome_aligned += "M" * (i[1] + 1) 
				else:
					right_anchorsize += i[1]
					right_read_anchor += self.readseq[readpos:readpos + i[1]]
					right_genome_aligned += "M" * (i[1] + 1) 
				readpos += i[1]
				genomepos += i[1]
			elif i[0] == 1:
				'''
				If insertion, add to readpos
				'''
				readpos += i[1]
			elif i[0] == 2:
				'''
				If deletion, add to anchor size
				'''
				if gap_seen < 1:
					left_anchorsize += i[1]
				else:
					right_anchorsize += i[1]
				genomepos += i[1]
			elif i[0] == 3:
				gap_seen += 1
				gapsize += i[1]
			else:
				pass #quit("Don't recognize cigar code")

		junc_left_side = self.start + left_anchorsize + 1
		junc_right_side = self.start + left_anchorsize + gapsize
		self.junc_left_side = junc_left_side
		self.junc_right_side = junc_right_side
		
		self.left_genome_aligned = left_genome_aligned
		self.right_genome_aligned = right_genome_aligned
		self.left_read_anchor = left_read_anchor
		self.right_read_anchor = right_read_anchor
		self.gapsize = gapsize

	
		""" 
		Try to get strand from SAM file first
		If it can't do it, use donor/acceptor motifs
		If still no, use *
		"""
		keys = []
		values = []
		for tag in tags:
			keys.append(tag[0])
			values.append(tag[1])
		tagdict = dict(zip(keys, values))
		try:
			strand = tagdict['XS']
			self.strand = strand
		except:
			self.strand = "*"
		
		self.juncid = self.chr + ":" + str(junc_left_side) + "_" + str(junc_right_side) + ":" + self.strand

def subdivideCigar(cigar):
	# Get gap indices
	gaps = []
	counter = 0
	for i in cigar:
		if i[0] == 3: gaps.append(counter)
		counter += 1	
	if gaps:
		"""
		If there are no gaps(juncs)
		return empty set
		"""
		borders = [0]
		for i in range(len(gaps[:-1])):
			borders.append(gaps[i+1])
			borders.append(gaps[i] + 1)
		borders.append(len(cigar))
		
		# Define subcigar ranges
		subcigars = []
		myjuncs = zip(borders[0::2], borders[1::2])
		for junc in myjuncs:
			subcigars.append(cigar[junc[0]:junc[1]])
	else:
		subcigars = []
	return subcigars


def quickcov(samfile,anchorsize):
	"""
	Takes a sam file as input
	Quickly gets coverage
	"""
	JTAB = collections.defaultdict(int)
	UNFILT_JTAB = collections.defaultdict(int)
	zero_anchor_warnings = 0
	for alignedread in samfile:
		if (len(alignedread.cigar) > 1):
			# Note that alignedread.is_reverse does not work right to get strand
			#strand = alignedread.tags[1][1] 
			mytid = alignedread.tid
			chr = samfile.getrname(mytid)
			start = alignedread.pos
			offset = alignedread.pos
			cigar = alignedread.cigar
			readseq = alignedread.query

			subcigars = subdivideCigar(cigar)

			for cigar in subcigars:
				j1 = JuncBasic(chr,start,cigar,readseq,alignedread.tags)
				'''
				For multi-gap cigars, you have to add to the start
				for the next one
				'''
				start += int(len(j1.left_genome_aligned))
				start += j1.gapsize

				juncid = j1.juncid

				
				'''
				Apply a restriction on anchor size
				to count the junction
				'''
				min_anchor = min(len(j1.left_read_anchor),len(j1.right_read_anchor))

				'''
				Also count unfiltered (no anchor cutoff)
				'''

				if min_anchor < 1:
					'''
					Warn when anchor size is zero
					For example, cigar 76M54354N
					These are errors, and shouldn't count toward coverage
					'''
					zero_anchor_warnings += 1
				else: 
					UNFILT_JTAB[juncid] += 1; # Total junction spanning reads


				if min_anchor >= anchorsize:
				
					JTAB[juncid] += 1; # Total junction spanning reads
	
				else:
					pass

	if zero_anchor_warnings > 0:
		print "[ WARNING ] ", zero_anchor_warnings, "alignments with zero anchor coverage excluded"
	
	return JTAB,UNFILT_JTAB

def tab_to_dict(tabfile):
	"""
	Generic make a dict from a table
	Assumes first column has key
	and there are column headers
	"""
	mytab = {}
	lines = csv.reader(open(tabfile, 'rb'), delimiter='\t')
	linecount = 0
	for line in lines:
		if (linecount < 1):
			"""
			First line is column header - use as keys
			"""
			keys = line
		else: 
			values = line
			linedict = dict(zip(keys, values))
			firstfield = str(values[0])
			# Remove whitespace
			id = firstfield.strip()
			mytab[id] = linedict 
			#print "adding to ",linedict['juncid']
			#print linedict
		linecount += 1
	return mytab

def intron_readthrough(myjuncs,samfile):
	IRT = collections.defaultdict(lambda : collections.defaultdict(dict))
	overhang = 8
	'''
	Get read length from first alignment
	'''
	for alignedread in samfile:
		readlength = alignedread.rlen
		break
	for juncid in myjuncs:

		j1 = Junctionid(juncid)

		# Check left side
		lirt = 0
		rangestart = j1.start - readlength - overhang
		rangeend = j1.start - overhang
		if (rangestart < 0): rangestart = 0
		# Need this for cases where a junction is near 
		# the end of a chromosome
		
		
		# Get all reads in the region where intron read-thru reads
		# could reside.
		# Count all reads that start in the correct range and have no gaps.
		reads = samfile.fetch( j1.chr, rangestart, rangeend )		
		for read in reads:
			if (rangeend > read.pos > rangestart): 
				cigar = read.cigar
				gaps = 0
				if len(cigar) > 1:
					for i in cigar:
						if i[0] == 3: gaps += 1
				if gaps < 1: 
					lirt += 1
		# Check right side
		rirt = 0
		rangestart = j1.end - readlength + overhang
		rangeend = j1.end - overhang
		if (rangestart < 0): rangestart = 0
		reads = samfile.fetch( j1.chr, rangestart, rangeend )
		for read in reads:
			if (rangeend > read.pos > rangestart): 
				cigar = read.cigar
				gaps = 0
				if len(cigar) > 1:
					for i in cigar:
						if i[0] == 3: gaps += 1
				if gaps < 1: 
					rirt += 1
		IRT[juncid]['lirt'] = lirt
		IRT[juncid]['rirt'] = rirt
		IRT[juncid]['irt'] = lirt + rirt
	return IRT


################################
################################
################################
################################
################################
class MyParser(argparse.ArgumentParser):
    def error(self, message):
        sys.stderr.write('error: %s\n' % message)
        #sys.stderr.write(desc)
        self.print_help()
        sys.exit(2)

def parse_options(desc):
	#parser=MyParser(description=desc, formatter_class=argparse.ArgumentDefaultsHelpFormatter)
	parser=MyParser(description=desc, formatter_class=argparse.RawTextHelpFormatter)
	#parser = argparse.ArgumentParser(description=desc, formatter_class=RawTextHelpFormatter)
	parser.add_argument('-i', help='BAM file name', action="store", dest="i")
	parser.add_argument('-jlist',action="store", dest="jlist",
		help="Curated junction list\n"
		"A table with >= 1 column, with column names\n"
		"It must have a column named 'juncid'\n"
		"Any additional columns are carried over to the new jtab ")
	parser.add_argument('-jtab', action="store", dest="jtab", 
		help="junctiontab (jtab)\n"
		"From first pass analysis of the BAM file supplied")
	parser.add_argument('-a', help='Anchor size, default=8', action="store", type=int, dest="a", default=8)
	parser.add_argument('-o', help="Output directory, default='curated_juncs'", action="store", dest="o", default="curated_juncs")

	args = parser.parse_args()
	if len(sys.argv)==1:
		parser.print_help()
		sys.exit(1)
	return args

# Initialize parameters
desc = '''
-----------------------------------------------------------------
make_curated_jtab

Takes a table or list of curated junctions, a BAM file, and a jtab.
It calculates IRT and neighbor coverage for junctions that were 
not detected in the first pass.  Outputs a new jtab, with results 
only for each junction in the list of curated junctions.
-----------------------------------------------------------------
'''

args = parse_options(desc)
bamfile = args.i
anchorsize = args.a
jlist = args.jlist
jtab = args.jtab
outfile = args.o


#~~~~~~~~~~~~~~~~~~~
# Prepare output directory
#~~~~~~~~~~~~~~~~~~~
output_dir = outfile
spanki_utils.prepare_basic_output_dir(output_dir)


#~~~~~~~~~~~~~~~~~~~
# Prepare output file
#~~~~~~~~~~~~~~~~~~~
# Prepare output file names
juncs_out_name = output_dir + "/juncs.all"
juncs_out = open(juncs_out_name, "w")

def main():
	
	print "#####################################################"
	print "########       make_curated_jtab             ########"
	print "#####################################################"
 	#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	#~~~~~~~~~~~~~~~~~~~
	# Load junction from first pass
	#~~~~~~~~~~~~~~~~~~~
	jdict = tab_to_dict(jtab)
	#~~~~~~~~~~~~~~~~~~~
	# Load reference junction list
	#~~~~~~~~~~~~~~~~~~~
	reflist = tab_to_dict(jlist)

	# Find the junctions in jlist that are not in jtab

	keys1 = jdict.keys()
	keys2 = reflist.keys()

	#print "Getting juncs in reflist not in jtab"
	#keyoverlap = [x for x in keys2 if x not in keys1]
	#counter = len(keyoverlap)

	## The above works faster if done with hash keys
	# 'myjuncs' will be the set of junctions to calculate irt on
	myjuncs = []
	for juncid in keys2:
		try:
			jdict[juncid]
		except KeyError:
			myjuncs.append(juncid)	

	
	#print >> sys.stderr, len(keys1), "in junction table,", len(keys2), "in OK list,", len(myjuncs), "juncs to get data for"
	print >> sys.stderr, "[%s] %s juncs in junction table, %s in OK list, %s juncs to get data for" % (spanki_utils.timestamp(),len(keys1), len(keys2),len(myjuncs))
	#print "Getting irt for these juncs:"
	#for x in myjuncs:
	#	print x
	
	#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	# Making a covbyedge hash from input jtab
	#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	print >> sys.stderr, "[%s] Making a donor/acceptor neighbor coverage hash" % (spanki_utils.timestamp())
	#print >> sys.stderr, "[%s] There are"  % (spanki_utils.timestamp()), len(keys1), "juncids in the OKlist" % (spanki_utils.timestamp())
	covbyedge = collections.defaultdict(lambda : collections.defaultdict(dict))

	#counter = 0
	for juncid in keys1:
		"""
		Read in data from the first pass jtab
		Use data to make a new covbyedge hash
		This function will not add new coverage to this hash, but an undetected junction
		will get a value for doncov for example
		"""
		j1 = Junctionid(juncid)
		#counter += 1
		#print "\t", counter
		#donid = j1.donid
		#accid = j1.accid
		if covbyedge[j1.donid]:
			covbyedge[j1.donid] += int(jdict[juncid]['cov'])
		else:
			covbyedge[j1.donid] = int(jdict[juncid]['cov'])
		if covbyedge[j1.accid]:
			covbyedge[j1.accid] += int(jdict[juncid]['cov'])
		else:
			covbyedge[j1.accid] = int(jdict[juncid]['cov'])

	#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	# IRT
	#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	bamfh = pysam.Samfile( bamfile, "rb" )
	#for alignedread in samfile:
	# Need some kind of iterator to getread length from first alignment in sam
	#print >> sys.stderr, "Getting details for", len(myjuncs), "that were not detected in this sample" 
	print >> sys.stderr, "[%s] Getting details for %s junctions that were not detected in this sample"  % (spanki_utils.timestamp(),len(myjuncs))
	print >> sys.stderr, "[%s] Getting intron read-though (IRT), may take awhile" % (spanki_utils.timestamp())	
	IRT = intron_readthrough(myjuncs,bamfh)
	"""
	Get IRT for all juncs:
	Redundantly calculates IRT for data in first pass jtab
	"""
	bamfh.close()
	print >> sys.stderr, "[%s] Done getting IRT" % (spanki_utils.timestamp())

	# For consistency, report these descriptive fields first in this order in every junction table:
	# 'dinucleotide','intron_size', 'annostatus','gmcode','regcode','geneassign','geneassignL','geneassignR'

	#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	# Now compile the results
	#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	# First show how you can get in hte myjuncs list
	print >> sys.stderr, "Printing results table"
	print >> juncs_out, "juncid\tdinucleotide\tintron_size\tannostatus\tgmcode\tregcode\tgeneassign\tcov\tlirt\trirt\tirt\tdncov\tancov"
	
	for juncid in sorted(keys2):
		try:
			"""
			Try getting the data from the first pass jtab
			If its not there, look in the new table
			"""
			results = [juncid, jdict[juncid]['dinucleotide'], jdict[juncid]['intron_size'], jdict[juncid]['annostatus'], jdict[juncid]['gmcode'], jdict[juncid]['regcode'], jdict[juncid]['geneassign'], jdict[juncid]['cov'], jdict[juncid]['lirt'], jdict[juncid]['rirt'], jdict[juncid]['irt'], jdict[juncid]['dncov'], jdict[juncid]['ancov']]
			print >> juncs_out, ('\t'.join(map(str,results)))
		except KeyError:
			#myjuncs.append(juncid)	
			j1 = Junctionid(juncid)
			donid = j1.donid
			accid = j1.accid
			if covbyedge[donid]: dncov = covbyedge[donid]
			else: dncov = 0
			if covbyedge[accid]: ancov = covbyedge[accid]
			else: ancov = 0
			results = [juncid, reflist[juncid]['dinucleotide'],  reflist[juncid]['intron_size'],  reflist[juncid]['annostatus'],  reflist[juncid]['gmcode'],  reflist[juncid]['regcode'], reflist[juncid]['geneassign'], 0, IRT[juncid]['lirt'], IRT[juncid]['rirt'], IRT[juncid]['irt'], dncov, ancov]
			#print(results, sep='\t')
			print >> juncs_out, ('\t'.join(map(str,results)))

	quit("done")


if __name__ == "__main__":
    sys.exit(main())

